// automatically generated by the FlatBuffers compiler, do not modify
extern crate flatbuffers;
use self::flatbuffers::{EndianScalar, Follow};
use super::*;
use std::cmp::Ordering;
use std::mem;
// struct Position, aligned to 4
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct Position(pub [u8; 8]);
impl Default for Position {
    fn default() -> Self {
        Self([0; 8])
    }
}
impl std::fmt::Debug for Position {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        f.debug_struct("Position")
            .field("longtitude", &self.longtitude())
            .field("latitude", &self.latitude())
            .finish()
    }
}

impl flatbuffers::SimpleToVerifyInSlice for Position {}
impl flatbuffers::SafeSliceAccess for Position {}
impl<'a> flatbuffers::Follow<'a> for Position {
    type Inner = &'a Position;
    #[inline]
    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
        <&'a Position>::follow(buf, loc)
    }
}
impl<'a> flatbuffers::Follow<'a> for &'a Position {
    type Inner = &'a Position;
    #[inline]
    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
        flatbuffers::follow_cast_ref::<Position>(buf, loc)
    }
}
impl<'b> flatbuffers::Push for Position {
    type Output = Position;
    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(self as *const Position as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}
impl<'b> flatbuffers::Push for &'b Position {
    type Output = Position;

    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(*self as *const Position as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for Position {
    #[inline]
    fn run_verifier(
        v: &mut flatbuffers::Verifier,
        pos: usize,
    ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
        use self::flatbuffers::Verifiable;
        v.in_buffer::<Self>(pos)
    }
}
impl<'a> Position {
    #[allow(clippy::too_many_arguments)]
    pub fn new(longtitude: f32, latitude: f32) -> Self {
        let mut s = Self([0; 8]);
        s.set_longtitude(longtitude);
        s.set_latitude(latitude);
        s
    }

    pub fn longtitude(&self) -> f32 {
        let mut mem = core::mem::MaybeUninit::<f32>::uninit();
        unsafe {
            core::ptr::copy_nonoverlapping(
                self.0[0..].as_ptr(),
                mem.as_mut_ptr() as *mut u8,
                core::mem::size_of::<f32>(),
            );
            mem.assume_init()
        }
        .from_little_endian()
    }

    pub fn set_longtitude(&mut self, x: f32) {
        let x_le = x.to_little_endian();
        unsafe {
            core::ptr::copy_nonoverlapping(
                &x_le as *const f32 as *const u8,
                self.0[0..].as_mut_ptr(),
                core::mem::size_of::<f32>(),
            );
        }
    }

    pub fn latitude(&self) -> f32 {
        let mut mem = core::mem::MaybeUninit::<f32>::uninit();
        unsafe {
            core::ptr::copy_nonoverlapping(
                self.0[4..].as_ptr(),
                mem.as_mut_ptr() as *mut u8,
                core::mem::size_of::<f32>(),
            );
            mem.assume_init()
        }
        .from_little_endian()
    }

    pub fn set_latitude(&mut self, x: f32) {
        let x_le = x.to_little_endian();
        unsafe {
            core::ptr::copy_nonoverlapping(
                &x_le as *const f32 as *const u8,
                self.0[4..].as_mut_ptr(),
                core::mem::size_of::<f32>(),
            );
        }
    }
}
